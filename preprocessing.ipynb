{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install torch_geometric\n",
    "!pip install dipy\n",
    "!pip install boto3"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "import os\n",
    "from dipy.io import read_bvals_bvecs\n",
    "from dipy.core.gradients import gradient_table\n",
    "from dipy.reconst.dti import TensorModel\n",
    "from dipy.io.image import load_nifti\n",
    "from dipy.reconst.csdeconv import auto_response_ssst, ConstrainedSphericalDeconvModel\n",
    "from dipy.direction import ProbabilisticDirectionGetter\n",
    "from dipy.data import default_sphere\n",
    "from dipy.tracking import utils\n",
    "from dipy.tracking.local_tracking import LocalTracking\n",
    "from dipy.io.image import save_nifti\n",
    "from dipy.tracking.stopping_criterion import ThresholdStoppingCriterion\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import pickle\n",
    "from dipy.tracking import Streamlines\n",
    "from dipy.segment.clustering import QuickBundles\n",
    "import boto3\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from dipy.align.imaffine import transform_centers_of_mass\n",
    "from scipy.ndimage import affine_transform\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dipy.tracking.streamline import length, values_from_volume\n",
    "\n"
   ],
   "id": "18e059d27dc6f816"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "id": "7c2a8c96f5ff0bc9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "aws_access_key_id = ''\n",
    "aws_secret_access_key = ''\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "bucket = 'hcp-openaccess'\n",
    "\n",
    "\n",
    "s3 = session.client('s3')"
   ],
   "id": "f5ccdc115a0d3daa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Farthest Point downsampling\n",
    "def downsample(subj_dir):\n",
    "    bvals = np.loadtxt(subj_dir / \"bvals\")\n",
    "    bvecs = np.loadtxt(subj_dir / \"bvecs\")\n",
    "\n",
    "    nonzero_idx = np.where(bvals > 100)[0]\n",
    "    bvecs_nonzero = bvecs[:, nonzero_idx].T  # Shape: (N, 3)\n",
    "\n",
    "    bvecs_nonzero /= np.linalg.norm(bvecs_nonzero, axis=1, keepdims=True) + 1e-6 # Normalize vectors to unit length\n",
    "\n",
    "    n_keep = len(bvecs_nonzero) // 3\n",
    "    print(f\"Keeping {n_keep} directions out of {len(bvecs_nonzero)}\")\n",
    "\n",
    "\n",
    "    selected_idx = [np.random.randint(len(bvecs_nonzero))] # Initialize selection with a random point\n",
    "    distances = pairwise_distances(bvecs_nonzero, bvecs_nonzero[selected_idx], metric='cosine').squeeze()\n",
    "\n",
    "    for _ in range(1, n_keep):\n",
    "        idx = np.argmax(distances)\n",
    "        selected_idx.append(idx)\n",
    "        new_distances = pairwise_distances(bvecs_nonzero, [bvecs_nonzero[idx]], metric='cosine').squeeze()\n",
    "        distances = np.minimum(distances, new_distances)\n",
    "\n",
    "    selected_idx_full = list(np.where((bvals >= 0) & (bvals <= 100))[0]) + [nonzero_idx[i] for i in selected_idx]\n",
    "\n",
    "    img = nib.load(subj_dir / \"data.nii.gz\")\n",
    "    data = img.get_fdata()\n",
    "\n",
    "    subset_data = data[..., selected_idx_full]\n",
    "    subset_bvals = bvals[selected_idx_full]\n",
    "    subset_bvecs = bvecs[:, selected_idx_full]\n",
    "\n",
    "    subset_img = nib.Nifti1Image(subset_data, img.affine)\n",
    "    nib.save(subset_img, subj_dir / \"dwi_subsampled.nii.gz\")\n",
    "    np.savetxt(subj_dir / \"dwi_subsampled.bval\", subset_bvals[np.newaxis, :], fmt='%.0f')\n",
    "    np.savetxt(subj_dir / \"dwi_subsampled.bvec\", subset_bvecs, fmt='%.6f')"
   ],
   "id": "c448bafcf726e73b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_streamlines_and_FA(subj_dir):\n",
    "    DATA = subj_dir / \"dwi_subsampled.nii.gz\"\n",
    "    BVAL = str(subj_dir / \"dwi_subsampled.bval\")\n",
    "    BVEC = str(subj_dir / \"dwi_subsampled.bvec\")\n",
    "    MASK = subj_dir / \"nodif_brain_mask.nii.gz\"\n",
    "\n",
    "    data, affine = load_nifti(DATA)\n",
    "    mask, _ = load_nifti(MASK)\n",
    "    bvals,bvecs = read_bvals_bvecs(BVAL,BVEC)\n",
    "    gtab = gradient_table(bvals,bvecs,b0_threshold=100)\n",
    "\n",
    "    tensor_model = TensorModel(gtab)\n",
    "    tensor_fit = tensor_model.fit(data, mask=mask)\n",
    "\n",
    "    FA = tensor_fit.fa\n",
    "\n",
    "    save_nifti(subj_dir / \"fa_map.nii.gz\", FA, affine)\n",
    "\n",
    "    stopping_criterion = ThresholdStoppingCriterion(FA, 0.2)\n",
    "    wm_mask = (FA>0.2) & (mask>0)\n",
    "\n",
    "    response, ratio = auto_response_ssst(gtab, data, roi_radii=10, fa_thr=0.7)\n",
    "    csd_model = ConstrainedSphericalDeconvModel(gtab, response)\n",
    "    csd_fit = csd_model.fit(data, mask=mask)\n",
    "\n",
    "    prob_dg = ProbabilisticDirectionGetter.from_shcoeff(csd_fit.shm_coeff, max_angle=30., sphere=default_sphere)\n",
    "    seeds = utils.random_seeds_from_mask(wm_mask, affine)\n",
    "\n",
    "    streamlines_generator = LocalTracking(\n",
    "        prob_dg,\n",
    "        stopping_criterion,\n",
    "        seeds,\n",
    "        affine,\n",
    "        step_size=0.5\n",
    "    )\n",
    "    streamlines = Streamlines(tqdm(itertools.islice(streamlines_generator, 100000)))\n",
    "\n",
    "    with open(str(subj_dir / \"streamlines.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(streamlines, f)\n",
    "\n",
    "    return streamlines, affine"
   ],
   "id": "d3070c79a81018fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#aligns atlas\n",
    "def align_images(subj_dir):\n",
    "    moving_img = nib.load(subj_dir / \"aparc+aseg.nii.gz\")\n",
    "    moving_data = moving_img.get_fdata()\n",
    "    moving_affine = moving_img.affine\n",
    "\n",
    "    fixed_img = nib.load(subj_dir / \"fa_map.nii.gz\")\n",
    "    fixed_data = fixed_img.get_fdata()\n",
    "    fixed_affine = fixed_img.affine\n",
    "\n",
    "    #align center of mass\n",
    "    c_of_mass = transform_centers_of_mass(fixed_data, fixed_affine,\n",
    "                                      moving_data, moving_affine)\n",
    "    transform_affine = c_of_mass.affine\n",
    "    affine_transform_matrix = np.linalg.inv(fixed_affine) @ transform_affine @ moving_affine\n",
    "\n",
    "    resampled = affine_transform(\n",
    "        moving_data,\n",
    "        matrix=np.linalg.inv(affine_transform_matrix[:3, :3]),\n",
    "        offset=affine_transform_matrix[:3, 3],\n",
    "        output_shape=fixed_data.shape,\n",
    "        order=0  # NEAREST NEIGHBOR\n",
    "    )\n",
    "\n",
    "    resampled_img = nib.Nifti1Image(resampled, fixed_affine)\n",
    "    nib.save(resampled_img, subj_dir / \"aparc+aseg_in_fa_space.nii.gz\")\n"
   ],
   "id": "29c88e8a65a598e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def filter_streamlines_by_length(streamlines, min_len=10, max_len=250):\n",
    "    lengths = list(length(streamlines))\n",
    "    mask = np.logical_and(np.array(lengths) > min_len,\n",
    "                          np.array(lengths) < max_len)\n",
    "    return streamlines[mask]"
   ],
   "id": "697764886d5c07e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def generate_graph(subj_dir):\n",
    "    with open(subj_dir / \"streamlines.pkl\", \"rb\") as f:\n",
    "        streamlines = pickle.load(f)\n",
    "    streamlines = Streamlines(streamlines)\n",
    "\n",
    "    roi_img = nib.load(subj_dir / \"aparc+aseg_in_fa_space.nii.gz\")\n",
    "    roi_data = roi_img.get_fdata().astype(int)\n",
    "    roi_affine = roi_img.affine\n",
    "\n",
    "    fa_img = nib.load(subj_dir / \"fa_map.nii.gz\")\n",
    "    fa_data= fa_img.get_fdata()\n",
    "\n",
    "    streamlines = filter_streamlines_by_length(streamlines)\n",
    "    qb = QuickBundles(threshold=10.0)\n",
    "    clusters = qb.cluster(streamlines)\n",
    "    filtered_clusters = [c for c in clusters if len(c) > 20]\n",
    "\n",
    "    print(\"Number of clusters:\", len(filtered_clusters))\n",
    "\n",
    "    #graph construction\n",
    "\n",
    "    total_streamlines = sum(len(c) for c in filtered_clusters)\n",
    "    cluster_feats = []\n",
    "    cluster_roi_edges = defaultdict(set)\n",
    "\n",
    "    for idx, cluster in enumerate(filtered_clusters):\n",
    "        cluster_streamlines = [streamlines[i] for i in cluster.indices]\n",
    "        all_points = np.concatenate(cluster_streamlines)\n",
    "\n",
    "        fa_vals = values_from_volume(fa_data, cluster_streamlines, roi_affine)\n",
    "        fa_vals = np.concatenate(fa_vals)\n",
    "        mean_fa = np.mean(fa_vals)\n",
    "        pos = len(cluster.indices) / total_streamlines\n",
    "\n",
    "        cluster_feats.append([mean_fa, pos])\n",
    "\n",
    "        voxel_coords = np.round(nib.affines.apply_affine(np.linalg.inv(roi_affine), all_points)).astype(int)\n",
    "        valid_mask = (\n",
    "            (voxel_coords[:, 0] >= 0) & (voxel_coords[:, 0] < roi_data.shape[0]) &\n",
    "            (voxel_coords[:, 1] >= 0) & (voxel_coords[:, 1] < roi_data.shape[1]) &\n",
    "            (voxel_coords[:, 2] >= 0) & (voxel_coords[:, 2] < roi_data.shape[2])\n",
    "        )\n",
    "        voxel_coords = voxel_coords[valid_mask]\n",
    "        roi_labels = roi_data[voxel_coords[:, 0], voxel_coords[:, 1], voxel_coords[:, 2]]\n",
    "        unique_roi_labels = np.unique(roi_labels)\n",
    "        for roi in unique_roi_labels:\n",
    "            if roi != 0:\n",
    "                cluster_roi_edges[idx].add(roi)\n",
    "\n",
    "    roi_labels = np.unique(roi_data)\n",
    "    roi_labels = roi_labels[roi_labels != 0]\n",
    "\n",
    "    roi_label_to_index = {label: idx for idx, label in enumerate(roi_labels)} # turn into consecutive indices\n",
    "\n",
    "    one_hot_size = len(roi_labels)\n",
    "    roi_feats = []\n",
    "\n",
    "    for label in roi_labels:\n",
    "        roi_mask = roi_data == label\n",
    "        fa_vals = fa_data[roi_mask]\n",
    "        mean_fa = np.mean(fa_vals)\n",
    "\n",
    "        # One-hot vector using remapped index\n",
    "        one_hot = np.zeros(one_hot_size)\n",
    "        one_hot[roi_label_to_index[label]] = 1\n",
    "\n",
    "        # Combine one-hot with mean FA\n",
    "        feature = np.concatenate([one_hot, [mean_fa]])\n",
    "        roi_feats.append(feature)\n",
    "\n",
    "    cluster_feats = torch.tensor(cluster_feats, dtype=torch.float)\n",
    "    roi_feats = torch.tensor(roi_feats, dtype=torch.float)\n",
    "\n",
    "    data = HeteroData()\n",
    "\n",
    "    data['cluster'].x = cluster_feats\n",
    "    data['roi'].x = roi_feats\n",
    "\n",
    "    cluster_to_roi_edges = []\n",
    "\n",
    "    for cluster_idx, roi_label_set in cluster_roi_edges.items():\n",
    "        for roi_label in roi_label_set:\n",
    "            roi_idx = roi_label_to_index[roi_label]\n",
    "            cluster_to_roi_edges.append([cluster_idx, roi_idx])\n",
    "\n",
    "    edge_index = torch.tensor(cluster_to_roi_edges, dtype=torch.long).t().contiguous()\n",
    "    data[('cluster', 'intersects', 'roi')].edge_index = edge_index\n",
    "    reverse_edges = edge_index[[1, 0], :]\n",
    "    data[('roi', 'intersects_rev', 'cluster')].edge_index = reverse_edges\n",
    "\n",
    "    return data\n",
    "\n"
   ],
   "id": "9287c337adc114ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "required_files = [\n",
    "    \"data.nii.gz\",\n",
    "    \"bvals\",\n",
    "    \"bvecs\",\n",
    "    \"nodif_brain_mask.nii.gz\",\n",
    "    \"aparc+aseg.nii.gz\"\n",
    "]\n",
    "\n",
    "delete_files = [\n",
    "    \"data.nii.gz\",\n",
    "    \"bvals\",\n",
    "    \"bvecs\",\n",
    "    \"nodif_brain_mask.nii.gz\",\n",
    "    \"dwi_subsampled.nii.gz\",\n",
    "    \"dwi_subsampled.bval\",\n",
    "    \"dwi_subsampled.bvec\"\n",
    "]\n",
    "\n",
    "save_dir = Path('/content/drive/MyDrive/HCP Data')\n",
    "raw_dir = save_dir / 'raw_data'\n",
    "log_file = save_dir / 'logs/processed_subjects.txt'\n",
    "\n",
    "raw_dir.mkdir(parents=True, exist_ok=True)\n",
    "log_file.parent.mkdir(exist_ok=True)\n",
    "\n",
    "if log_file.exists():\n",
    "    with open(log_file) as f:\n",
    "        processed = set(line.strip() for line in f)\n",
    "else:\n",
    "    processed = set()\n",
    "\n",
    "\n",
    "df = pd.read_csv('/content/drive/MyDrive/HCP Data/behavioral_data.csv')\n",
    "filtered_df = df[df['3T_dMRI_Compl'] == True]\n",
    "subject_list = filtered_df['Subject'].astype(str).tolist()\n",
    "\n",
    "\n",
    "\n",
    "for subj in subject_list:\n",
    "    if subj in processed:\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing subject: {subj}\")\n",
    "    subj_dir = raw_dir / subj\n",
    "    subj_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    for fname in required_files:\n",
    "        key = f\"HCP_1200/{subj}/T1w/Diffusion/{fname}\"\n",
    "        local_path = subj_dir / fname\n",
    "        s3.download_file(bucket, key, str(local_path))\n",
    "\n",
    "    downsample(subj_dir)\n",
    "\n",
    "    streamlines, affine = get_streamlines_and_FA(subj_dir)\n",
    "\n",
    "    align_images(subj_dir)\n",
    "\n",
    "    graph = generate_graph(subj_dir)\n",
    "\n",
    "    label = df.loc[df['Subject'] == int(subj), 'Gender'].values[0]\n",
    "\n",
    "    torch.save(graph, save_dir / f\"gender_graphs/{label}/{subj}.pt\")\n",
    "\n",
    "    for fname in delete_files:\n",
    "        file_path = subj_dir / fname\n",
    "        open(file_path, 'wb').close()\n",
    "        os.remove(file_path)\n",
    "\n",
    "\n",
    "    with open(log_file, \"a\") as f:\n",
    "        f.write(subj + \"\\n\")\n",
    "\n",
    "\n"
   ],
   "id": "b65986d074252f82"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
